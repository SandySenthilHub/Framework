# Software Requirement Specification: Enhanced Multi-Tenant Contact Center and Mobile Banking Analytics Platform

## 1. Introduction

### 1.1 Purpose

The purpose of this Software Requirement Specification (SRS) document is to provide a detailed description of the requirements for the Enhanced Multi-Tenant Contact Center and Mobile Banking Analytics Platform. This platform is designed to serve X Bank (TenantID=1) and Y Bank (TenantID=2) by integrating advanced Azure Cognitive Services, sophisticated Artificial Intelligence (AI) capabilities, fully customizable dashboards for various user roles (Admin, Hameed, Rishi), and a robust React-based frontend. This document will serve as the foundation for the design, development, and testing of the platform, ensuring that all stakeholders have a clear and common understanding of the system's functionalities, features, constraints, and goals. The specifications outlined herein aim to be comprehensive, measurable, and unambiguous, facilitating a streamlined development process and a final product that meets the explicit and implicit needs of the end-users and the business objectives of X Bank and Y Bank. The platform will build upon existing functionalities, including a multi-tenant Azure SQL Server backend, a FastAPI-based backend, and Power BI integration, while introducing significant enhancements to analytics, user experience, and operational efficiency.

### 1.2 Scope

The scope of this project encompasses the enhancement of an existing multi-tenant analytics platform. Key areas of development include the deep integration of Azure Cognitive Services for advanced data processing such as speech-to-text transcription, sentiment analysis, key phrase extraction, entity recognition, and tone detection for both English and Arabic languages. The platform will incorporate advanced AI and Machine Learning (ML) capabilities, including regression analysis for KPI prediction, clustering for customer and agent segmentation, anomaly detection for identifying outliers in operational data, and the utilization of automated neural networks via Azure AutoML for optimizing predictive models. A significant part of the scope is the development of fully customizable dashboards, allowing users like Admin, Hameed, and Rishi to personalize their data visualization experience through drag-and-drop widgets, configurable filters, and drill-down capabilities, with these customizations persisted in the Azure SQL Server database. Furthermore, the project includes the creation of a responsive and interactive React frontend that will display real-time analytics and integrate seamlessly with Azure Cognitive Services. The backend will be served by FastAPI, and the system will continue to leverage Power BI for reporting, now enhanced with Cognitive Services outputs. The scope also covers the necessary updates to the Azure SQL Server database schema to accommodate new data points from these enhanced services, the refinement of the synthetic data generator, the IVR analytics module, and the existing alerts system. The platform must be scalable to support future integration of internet banking KPIs and adhere to stringent security measures including row-level security and data encryption, despite not requiring initial user authentication for dashboard customization access (user selection via dropdown). Deliverables will include the database schema, FastAPI backend code, React frontend code, Power BI templates, a synthetic data generation script, an MLOps pipeline definition, the alert system specifications, IVR analytics functionalities, and comprehensive Azure deployment instructions.

### 1.3 Definitions, Acronyms, and Abbreviations

*   **AI**: Artificial Intelligence - The simulation of human intelligence processes by machines, especially computer systems.
*   **AHT**: Average Handle Time - A key contact center KPI measuring the average duration of a single transaction or interaction.
*   **API**: Application Programming Interface - A set of rules and protocols for building and interacting with software applications.
*   **AutoML**: Automated Machine Learning - The process of automating the end-to-end process of applying machine learning to real-world problems.
*   **CSAT**: Customer Satisfaction Score - A measure of how products and services supplied by a company meet or surpass customer expectation.
*   **DAX**: Data Analysis Expressions - A formula language used in Power BI and other Microsoft data analysis tools.
*   **FastAPI**: A modern, fast (high-performance) web framework for building APIs with Python 3.7+ based on standard Python type hints.
*   **IVR**: Interactive Voice Response - A technology that allows a computer to interact with humans through the use of voice and DTMF tones input via a keypad.
*   **JSON**: JavaScript Object Notation - A lightweight data-interchange format.
*   **KPI**: Key Performance Indicator - A measurable value that demonstrates how effectively a company is achieving key business objectives.
*   **LUIS**: Language Understanding Intelligent Service - A cloud-based API service that applies custom machine-learning intelligence to a user's conversational, natural language text to predict overall meaning, and pull out relevant, detailed information.
*   **ML**: Machine Learning - A type of artificial intelligence that provides systems the ability to automatically learn and improve from experience without being explicitly programmed.
*   **MLOps**: Machine Learning Operations - A set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently.
*   **PCA**: Principal Component Analysis - A statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.
*   **React**: A JavaScript library for building user interfaces.
*   **SRS**: Software Requirement Specification - A document that describes what the software will do and how it will be expected to perform.
*   **SQL**: Structured Query Language - A standard language for managing and manipulating databases.
*   **TenantID**: Tenant Identifier - A unique identifier assigned to each tenant (e.g., X Bank, Y Bank) in a multi-tenant architecture.

### 1.4 Overview

This SRS document is structured to provide a comprehensive overview of the Enhanced Multi-Tenant Contact Center and Mobile Banking Analytics Platform. Section 1, the Introduction, provides the purpose, scope, definitions, and an overview of this document. Section 2, Overall Description, will detail the product perspective, its core functions, characteristics of the intended users, operational constraints, and any assumptions and dependencies. Section 3 will delve into Specific Requirements, outlining all functional requirements such as multi-tenancy, contact center analytics, mobile banking analytics, Azure Cognitive Services integration, AI/ML capabilities, MLOps pipeline, customizable dashboards, frontend and backend specifications, Power BI integration, alerts, synthetic data generation, and IVR analytics. This section will also cover non-functional requirements including database specifications, scalability, security, deployment, and monitoring. Finally, Section 4 will cover Other Requirements, including the list of deliverables. Each requirement will be described in a manner that is clear, concise, verifiable, and measurable, ensuring that the development team can effectively implement the system and the testing team can validate its compliance with the specified criteria. The document aims to guide the project through its lifecycle, from conception to deployment and maintenance.




## 2. Overall Description

### 2.1 Product Perspective

The Enhanced Multi-Tenant Contact Center and Mobile Banking Analytics Platform is an evolution of an existing analytics solution. It is designed to operate within the Azure cloud ecosystem, leveraging a suite of Azure services for its backend, data processing, AI capabilities, and deployment. The platform serves as a sophisticated business intelligence and operational analytics tool for X Bank and Y Bank, providing them with deep insights into their contact center operations (handling 2,000 daily calls across three shifts in English and Arabic by 200 agents) and mobile banking services (tracking 100 distinct KPIs). This enhanced version significantly expands upon the previous system by deeply integrating Azure Cognitive Services for nuanced understanding of customer interactions (speech-to-text, sentiment, key phrases, entities, tone, IVR intent) and by incorporating advanced AI/ML models for predictive analytics, customer/agent clustering, and anomaly detection. The system will interface with the existing multi-tenant Azure SQL Server database, which will be updated to store new data types. The backend logic will be managed by a FastAPI application, ensuring high performance and scalability. The primary user interface will be a new React-based frontend, offering highly customizable dashboards tailored to individual users (Admin, Hameed, Rishi) without requiring traditional authentication, alongside continued support for Power BI for advanced reporting and visualization. The platform is self-contained in terms of its core functionalities but relies on Azure for its underlying infrastructure and specialized services. It is intended to be a critical tool for operational management, strategic decision-making, and improving customer experience for the tenant banks.

### 2.2 Product Functions

The platform will provide a comprehensive suite of functions designed to deliver actionable insights and enhance operational control. Key functions include:

1.  **Multi-Tenant Data Management**: Securely manage and segregate data for X Bank and Y Bank, ensuring data isolation and tenant-specific configurations through TenantID, row-level security, and database partitioning.
2.  **Contact Center Analytics**: Compute and display 90 distinct KPIs (20 critical, 20 medium, 50 low) for the contact center, covering aspects like Average Handle Time (AHT), Customer Satisfaction (CSAT), and agent performance. This includes processing and analyzing data from 2,000 daily calls (80% inbound, 20% outbound) across English and Arabic languages.
3.  **Mobile Banking Analytics**: Compute and display 100 distinct KPIs (20 critical, 20 medium, 60 low) related to mobile application usage and transaction patterns.
4.  **Azure Cognitive Services Integration**: Provide deep analytical capabilities by transcribing call audio (English and Arabic) with speaker diarization; performing sentiment analysis, key phrase extraction, and entity recognition on call transcripts and transaction feedback; detecting intents in IVR interactions using LUIS; and classifying call tones using custom ML models.
5.  **Advanced AI/ML Capabilities**: Implement regression models to predict KPIs; utilize clustering algorithms to segment agents and customers; employ anomaly detection techniques to identify unusual patterns in KPIs; and leverage Azure AutoML for optimizing predictive models. An MLOps pipeline will manage the lifecycle of these models.
6.  **Customizable Dashboards**: Allow users (Admin, Hameed, Rishi), identified via a dropdown selection, to create, modify, and save personalized dashboard configurations. This includes drag-and-drop widgets for KPIs, Cognitive Services outputs (sentiment, keywords, entities), and IVR patterns; configurable filters (tenant, date range, KPI type); and drill-down capabilities to view detailed data. Configurations will be stored as JSON in the `DashboardCustomizations` table.
7.  **React Frontend Interface**: Deliver a responsive and interactive user interface built with React, enabling dashboard customization, real-time visualization of analytics (including Cognitive Services outputs like sentiment scores and sankey diagrams for IVR paths), and drill-down into underlying data. The frontend will support trend analysis (day-on-day, month-on-month, year-on-year).
8.  **FastAPI Backend Services**: Expose robust and efficient API endpoints for all frontend functionalities, including KPI retrieval, transcript analysis, IVR pattern data, transaction details, dashboard customization management, and Cognitive Services analytics.
9.  **Power BI Integration**: Support real-time dashboards in Power BI, featuring KPI cards, sentiment heatmaps, word clouds for key phrases/entities, and IVR sankey diagrams. Enable drill-through to detailed reports and user-specific customizations via slicers.
10. **IVR Analytics**: Analyze IVR node selections, drop-off points, and customer interaction patterns, visualizing these paths using sankey diagrams.
11. **Alerting System**: Generate and deliver alerts for predefined KPI threshold breaches, anomalies detected by ML models, and high system load conditions (e.g., call volume exceeding 2,500). Alerts will be stored and managed via Azure Functions.
12. **Synthetic Data Generation**: Provide a Python-based script using Faker and Azure Text-to-Speech to generate realistic synthetic data for calls, transactions, transcriptions (including sentiment, key phrases, entities), and IVR interactions for testing and demonstration purposes. Logs of generated data will be stored.

### 2.3 User Characteristics

The platform is intended for use by specific roles within X Bank and Y Bank, each with varying analytical needs and technical expertise. The primary users are:

*   **Admin**: This user role typically represents a system administrator or a high-level manager with oversight over the entire platform for their respective tenant. They would require access to all KPIs, full customization capabilities for dashboards, and potentially administrative functions related to user configurations (though direct user management is out of scope for authentication). They are expected to have a good understanding of the business operations and data analytics.
*   **Hameed**: This user role represents a specific managerial or analytical profile, likely focused on particular aspects of the contact center or mobile banking operations. Hameed will require customizable dashboards tailored to their specific areas of responsibility, with the ability to drill down into details and generate custom reports. They are expected to be data-savvy and capable of interpreting complex analytics.
*   **Rishi**: Similar to Hameed, Rishi represents another distinct user profile with specific analytical needs. This user will also have full access to dashboard customization features to monitor KPIs and operational metrics relevant to their role. They are expected to be comfortable working with data visualization tools and analytical outputs.

All users, regardless of their specific role (Admin, Hameed, Rishi), will interact with the system primarily through the React frontend and potentially through Power BI dashboards. They are not expected to have deep programming or database administration skills. The system is designed to be user-friendly, with an intuitive interface for dashboard customization and data exploration. User identification for dashboard customization will be handled via a simple dropdown selection, bypassing traditional login mechanisms for this specific feature, with customizations persisted per selected user ID.

### 2.4 Constraints

The development and operation of the Enhanced Multi-Tenant Contact Center and Mobile Banking Analytics Platform will be subject to several constraints:

1.  **Technology Stack**: The platform must be developed using the specified technologies: Azure SQL Server for the database, FastAPI (Python) for the backend, React (JavaScript/TypeScript) for the frontend, and Power BI for advanced reporting. Azure Cognitive Services (Speech, Text Analytics, LUIS), Azure Machine Learning (including AutoML), and Azure Functions are mandated for their respective functionalities.
2.  **Azure Ecosystem**: The entire solution must be deployable and operable within the Microsoft Azure cloud environment. This includes leveraging Azure App Service for hosting the FastAPI backend, Azure Static Web Apps for the React frontend, and other relevant Azure services for database, ML, and alerting.
3.  **Multi-Tenancy**: The system must strictly enforce data isolation and security between X Bank (TenantID=1) and Y Bank (TenantID=2). All data and configurations must be tenant-specific, implemented via TenantID columns, row-level security, and database partitioning where appropriate.
4.  **Existing Infrastructure**: The platform enhances an existing system. Therefore, it must integrate with or build upon the existing multi-tenant Azure SQL Server database and potentially other existing components, ensuring backward compatibility or a clear migration path where necessary. The schema modifications outlined in the source document must be implemented.
5.  **No Initial Authentication for Dashboard Customization**: A specific constraint is that dashboard customization for users (Admin, Hameed, Rishi) will not involve a traditional authentication mechanism (username/password login). Instead, users will select their identifier from a dropdown menu to load and save their personalized dashboard configurations. Security for this aspect relies on the controlled environment and authorized access to the application itself.
6.  **Real-Time/Near Real-Time Processing**: Certain functionalities, such as call transcription and some KPI updates, are expected to operate in real-time or near real-time. The system architecture must support this low-latency processing, potentially using Azure Functions for event-driven tasks.
7.  **Language Support**: The platform must support both English and Arabic languages for contact center analytics, including speech-to-text transcription and potentially other Cognitive Services features.
8.  **Scalability for Internet Banking KPIs**: The system architecture and database design must be scalable to accommodate the future integration of KPIs related to internet banking operations without requiring major redesigns.
9.  **Data Volume and Performance**: The system must efficiently handle the specified data volumes (e.g., 2,000 calls per day, numerous mobile transactions) and provide responsive performance for dashboard loading, data querying, and analytics processing.
10. **Deliverables**: The project must produce all deliverables specified in the 

App Builder Prompt (Section 11 of the input document), including database schema, FastAPI code, React frontend, Power BI templates, synthetic data script, MLOps pipeline, alert system, IVR analytics, and Azure deployment instructions.

### 2.5 Assumptions and Dependencies

The successful development and operation of the Enhanced Multi-Tenant Contact Center and Mobile Banking Analytics Platform are based on the following assumptions and dependencies:

1.  **Azure Services Availability and Performance**: The platform heavily relies on various Azure services (SQL Server, App Service, Static Web Apps, Cognitive Services, Machine Learning, Functions, Monitor, Application Insights). It is assumed that these services will be available, performant, and operate as documented by Microsoft. Any outages or significant performance degradation in these Azure services will directly impact the platform.
2.  **Access to Existing Data Sources**: It is assumed that the development team will have necessary access to the existing Azure SQL Server database and any other relevant data sources required for integration and data migration (if applicable). The structure and quality of existing data are assumed to be adequate for the new enhancements.
3.  **Clarity of KPI Definitions**: The definitions and calculation logic for all 90 contact center KPIs and 100 mobile banking KPIs are assumed to be clearly defined and provided by the stakeholders (X Bank and Y Bank). Any ambiguity or changes in these definitions may impact development effort and timelines.
4.  **Availability of Subject Matter Experts**: Access to subject matter experts from X Bank and Y Bank is assumed for clarifications regarding business rules, KPI logic, user requirements, and validation of the implemented features.
5.  **Cognitive Services Keys and Endpoints**: Valid Azure Cognitive Services keys, endpoints, and necessary configurations (e.g., for LUIS apps, Custom Speech models) will be provided and maintained for the development, testing, and production environments. The quotas and limits of these services are assumed to be sufficient for the platform's load.
6.  **Network Connectivity**: Stable and sufficient network connectivity is assumed between all components of the system, including the frontend, backend, database, and external Azure services.
7.  **User Acceptance of "No Authentication" Model**: It is assumed that the specified users (Admin, Hameed, Rishi) and relevant stakeholders accept the approach of selecting user identity via a dropdown for dashboard customization, without traditional authentication, and understand its security implications.
8.  **Third-Party Libraries and Frameworks**: The project will utilize various third-party libraries and frameworks (e.g., React, FastAPI, Pydantic, Pandas, scikit-learn, Recharts, react-beautiful-dnd). It is assumed these tools will function as expected and that their licenses are compatible with the project's usage.
9.  **Synthetic Data Accuracy**: While the synthetic data generator aims to produce realistic data, it is assumed that this data is primarily for testing and development purposes and may not perfectly replicate all nuances of real-world operational data.
10. **Compliance with Data Privacy Regulations**: It is assumed that the tenant banks (X Bank and Y Bank) are responsible for ensuring that the data processed and stored by the platform complies with all relevant data privacy regulations (e.g., GDPR, CCPA, or local banking regulations). The platform will provide features like data encryption and row-level security to support compliance, but the overall responsibility lies with the tenants.
11. **Arabic Language Expertise**: For features involving the Arabic language (speech-to-text, custom speech models, potentially LUIS), it is assumed that expertise in Arabic dialects and banking terminology will be available to train and validate the models effectively.



## 3. Specific Requirements

### 3.1 Functional Requirements

#### 3.1.1 Multi-Tenancy

**FR-MT-001: Tenant Data Isolation**: The system shall ensure strict data isolation between tenants, specifically X Bank (TenantID=1) and Y Bank (TenantID=2). All data, including but not limited to call records, mobile transactions, KPI metrics, user customizations, and analytical results, must be associated with a specific TenantID. Users belonging to one tenant shall not, under any circumstances, be able to access or view data belonging to another tenant. This isolation must be enforced at the database level through mechanisms such as row-level security and database partitioning based on TenantID. Queries and API endpoints must incorporate TenantID filtering by default to prevent accidental data leakage.

**FR-MT-002: Tenant-Specific Configuration**: The platform shall support tenant-specific configurations where applicable. While core functionalities will be shared, certain parameters or settings (e.g., specific KPI definitions if they vary slightly, alert thresholds if business rules differ) might need to be configurable on a per-tenant basis. Such configurations must be stored and managed in a way that maintains tenant isolation.

**FR-MT-003: Scalability for New Tenants**: Although initially designed for X Bank and Y Bank, the underlying architecture for multi-tenancy should be designed with consideration for potential future scalability to onboard additional tenants with minimal architectural changes. This implies that the tenant identification and data segregation mechanisms should be robust and extensible.

**FR-MT-004: Tenant Identification in APIs and UI**: All API endpoints that deal with tenant-specific data must accept TenantID as a parameter or derive it implicitly from a secure context (though the latter is less applicable given the user selection model for dashboards). The user interface, particularly for administrative or overview functions, should clearly indicate the currently active tenant context if relevant, or allow selection/filtering by tenant where appropriate for users with cross-tenant visibility (if any such roles exist beyond the specified Admin, Hameed, Rishi per tenant).



#### 3.1.2 Contact Center Analytics

**FR-CCA-001: KPI Calculation - Critical**: The system shall calculate and store 20 distinct critical Key Performance Indicators (KPIs) for contact center operations for each tenant. These KPIs must include, but are not limited to, Average Handle Time (AHT) and Customer Satisfaction (CSAT). The exact list of 20 critical KPIs and their precise calculation formulas must be configurable and verifiable, based on data from the `Calls` and other relevant tables (e.g., `KPIMetrics`). Calculations must be accurate to two decimal places where applicable.

**FR-CCA-002: KPI Calculation - Medium**: The system shall calculate and store 20 distinct medium-priority KPIs for contact center operations for each tenant. An example includes Repeat Call Rate. The specific list of these 20 medium KPIs and their calculation logic must be clearly defined, configurable, and verifiable. Results should be stored in the `KPIMetrics` table and be accurate.

**FR-CCA-003: KPI Calculation - Low**: The system shall calculate and store 50 distinct low-priority KPIs for contact center operations for each tenant. An example includes Agent-Specific CSAT. The complete list of these 50 low-priority KPIs and their calculation methods must be documented, configurable, and verifiable, with results stored appropriately, likely in `KPIMetrics`.

**FR-CCA-004: Data Source and Granularity**: All contact center KPIs shall be derived from data related to the 2,000 daily calls (on average), considering the 80% inbound and 20% outbound call distribution, the 200 agents, and the three operational shifts. The system must be capable of processing call data in both English and Arabic. KPI data should be available at various granularities, such as per agent, per shift, per call type (inbound/outbound), and over different time periods (e.g., daily, weekly, monthly) to support trend analysis.

**FR-CCA-005: Real-time KPI Updates (Select KPIs)**: A subset of critical contact center KPIs (to be specified, e.g., current AHT, call queue length if applicable from data) shall be updated in near real-time, with a maximum latency of 5 minutes from the occurrence of the relevant event (e.g., call completion). Other KPIs may be calculated on a scheduled basis (e.g., hourly or daily).

**FR-CCA-006: Storage of KPI Metrics**: All calculated KPI values, along with their calculation timestamp, TenantID, KPIType, and relevant dimensions (e.g., AgentID, Date), shall be stored in the `KPIMetrics` table. The schema of this table must support efficient querying for dashboard display and reporting.

**FR-CCA-007: Historical KPI Data**: The system shall retain historical KPI data for a minimum period of 24 months to enable long-term trend analysis and comparative reporting. The performance of queries on historical data must be optimized.



#### 3.1.3 Mobile Banking Analytics

**FR-MBA-001: KPI Calculation - Critical**: The system shall calculate and store 20 distinct critical Key Performance Indicators (KPIs) for mobile banking operations for each tenant. An example includes App Login Success Rate. The precise list of these 20 critical KPIs and their calculation formulas must be clearly defined, configurable, and verifiable, based on data from the `MobileTransactions` and other relevant tables (e.g., `KPIMetrics`). Calculations must be accurate, typically to two decimal places where applicable.

**FR-MBA-002: KPI Calculation - Medium**: The system shall calculate and store 20 distinct medium-priority KPIs for mobile banking operations for each tenant. An example includes Login Failure Rate. The specific list of these 20 medium KPIs and their calculation logic must be documented, configurable, and verifiable. Results should be stored in the `KPIMetrics` table and be accurate.

**FR-MBA-003: KPI Calculation - Low**: The system shall calculate and store 60 distinct low-priority KPIs for mobile banking operations for each tenant. An example includes Transaction by Merchant Category. The complete list of these 60 low-priority KPIs and their calculation methods must be specified, configurable, and verifiable, with results stored appropriately, likely in `KPIMetrics`.

**FR-MBA-004: Data Source and Granularity**: All mobile banking KPIs shall be derived from data related to mobile application usage and transaction patterns, as captured in the `MobileTransactions` table. This includes data points such as `TransactionType`, `Amount`, `Status`, and `DeviceType`. KPI data should be available at various granularities, such as per user (anonymized or aggregated where necessary for privacy), per transaction type, per device type, and over different time periods (e.g., daily, weekly, monthly) to support comprehensive trend analysis and user behavior studies.

**FR-MBA-005: Real-time KPI Updates (Select KPIs)**: A subset of critical mobile banking KPIs (to be specified, e.g., current transaction success rate, new user registrations if tracked) shall be updated in near real-time, with a maximum latency of 5 minutes from the occurrence of the relevant event (e.g., transaction completion, app login). Other KPIs may be calculated on a scheduled basis (e.g., hourly or daily) depending on their nature and the business need for immediacy.

**FR-MBA-006: Storage of KPI Metrics**: All calculated mobile banking KPI values, along with their calculation timestamp, TenantID, KPIType, and relevant dimensions (e.g., UserID (anonymized if necessary), Date, TransactionType), shall be stored in the `KPIMetrics` table. The schema must support efficient querying for dashboard display, reporting, and analytical purposes.

**FR-MBA-007: Historical KPI Data**: The system shall retain historical mobile banking KPI data for a minimum period of 24 months to enable long-term trend analysis, comparative reporting, and the identification of seasonal patterns or long-term shifts in user behavior. Query performance on this historical data must be maintained at an acceptable level.

**FR-MBA-008: Feedback Analysis Integration**: Where mobile banking feedback is collected (e.g., post-transaction surveys, app store reviews if accessible), the system shall integrate sentiment scores, key phrases, and entities extracted from this feedback (as per Azure Cognitive Services integration) with relevant mobile banking KPIs. This will allow for a richer understanding of the drivers behind KPI movements, for instance, correlating a drop in transaction completion rates with negative sentiment expressed in feedback.



#### 3.1.4 Azure Cognitive Services Integration

**FR-ACS-001: Speech-to-Text (STT) Service Integration**: The system shall integrate with Azure Cognitive Services Speech Service to transcribe call audio recordings for both English and Arabic languages. The transcription process must support real-time or near real-time processing for live calls and batch processing for historical recordings. The accuracy of transcription for English must be at least 90% and for Arabic (including specific dialects if custom models are trained) must be at least 85% on a standard test set of domain-specific audio. The output transcriptions shall be stored in the `CallTranscriptions` table, linked to the respective `CallID`.

**FR-ACS-002: Speaker Diarization**: The STT service integration shall support speaker diarization to accurately distinguish between the agent's speech and the customer's speech within a single call recording. The output in `CallTranscriptions.SpeakerDiarization` must provide clear segmentation (e.g., timestamps and speaker labels like "Agent", "Customer") for at least 95% of calls where two distinct speakers are present. This information is crucial for calculating agent-specific talk time, customer talk time, and analyzing interaction dynamics.

**FR-ACS-003: Text Analytics - Sentiment Analysis**: The system shall utilize Azure Text Analytics service to perform sentiment analysis on call transcripts (stored in `CallTranscriptions.TranscriptText`) and any textual feedback from mobile transactions (e.g., comments or survey responses, if available and stored in `MobileTransactions`). The sentiment analysis must classify text as positive, neutral, or negative, and provide associated confidence scores. The sentiment score (e.g., a continuous value from -1 to 1, or discrete labels) and confidence scores shall be stored in `CallTranscriptions.SentimentScore` and the relevant field in `MobileTransactions`. The accuracy of sentiment classification must be at least 80% compared to human-annotated samples.

**FR-ACS-004: Text Analytics - Key Phrase Extraction**: The system shall use Azure Text Analytics to extract key phrases from call transcripts and mobile transaction feedback. These key phrases (e.g., “account issue,” “loan application,” “payment failed”) will help identify common topics and issues. The extracted key phrases shall be stored as a JSON array or comma-separated string in `CallTranscriptions.KeyPhrases` and the relevant field in `MobileTransactions`. The relevance of extracted key phrases must be validated, with at least 85% of extracted phrases deemed relevant by a human evaluator on a sample set.

**FR-ACS-005: Text Analytics - Entity Recognition**: The system shall employ Azure Text Analytics for named entity recognition (NER) on call transcripts and mobile transaction feedback. It must identify and categorize entities such as account numbers, dates, product names, organization names, and locations. Extracted entities shall be stored as a JSON array or structured format in `CallTranscriptions.Entities` and the relevant field in `MobileTransactions`. The NER accuracy (precision and recall for entity identification and categorization) must be at least 80% for predefined entity types relevant to the banking domain.

**FR-ACS-006: Language Understanding (LUIS) for IVR Intent Detection**: The system shall integrate with Azure LUIS to detect customer intents during IVR interactions. Based on the customer's spoken input or DTMF selections within the IVR system (data captured in `IVRInteractions`), LUIS models (to be trained) must identify intents like “check balance,” “transfer funds,” “report lost card,” etc. The detected intent shall be stored in `IVRInteractions.Intent`. The intent recognition accuracy must be at least 85% for the top 10 most frequent IVR intents.

**FR-ACS-007: Custom Speech Model Training and Usage**: For improved STT accuracy, especially for Arabic dialects and specific banking terminology, the system shall support the training and deployment of custom speech models using Azure Custom Speech service. The process for training, evaluating, and deploying these custom models must be documented. The system must utilize the best available model (standard or custom) for transcription based on language and tenant.

**FR-ACS-008: Tone Detection (Custom API/ML Model)**: The system shall implement or integrate a tone detection capability to classify the emotional tone of speakers (e.g., angry, neutral, happy, frustrated) in call transcripts. This may involve using Azure Machine Learning in conjunction with Cognitive Services, or a custom-trained model. The detected tone shall be stored in `CallTranscriptions.Tone`. The tone classification accuracy must be at least 75% for 3-5 distinct tone categories on a balanced test set.

**FR-ACS-009: Backend Integration for Cognitive Services**: The FastAPI backend shall include dedicated API endpoints to trigger and manage interactions with Azure Cognitive Services. These endpoints will handle tasks like submitting audio for transcription, text for analysis, and retrieving results. The integration must be robust, handle API errors gracefully (e.g., rate limits, authentication issues), and manage Azure credentials securely.

**FR-ACS-010: Frontend Display of Cognitive Services Results**: The React frontend shall be capable of displaying the outputs from Azure Cognitive Services in relevant dashboard widgets. This includes showing sentiment scores (e.g., as gauges, color-coded icons), lists of key phrases and entities, detected IVR intents, and identified tones. The display must be user-friendly and provide actionable insights.

**FR-ACS-011: Storage of Cognitive Services Outputs**: All results generated by Azure Cognitive Services (transcriptions, sentiment scores, key phrases, entities, speaker diarization data, detected intents, tones) must be persistently stored in the designated fields within the `CallTranscriptions`, `MobileTransactions`, and `IVRInteractions` tables in the Azure SQL Server database, linked to the original call, transaction, or IVR session.

**FR-ACS-012: Real-Time Processing for Cognitive Services**: For applicable services like real-time STT and sentiment analysis during a call, the system must process data with a maximum latency of 10 seconds from data availability to the result being available for display or storage. This may involve using Azure Functions for asynchronous processing triggered by events (e.g., new call audio segment available).



#### 3.1.5 Enhanced AI/ML Capabilities

**FR-AIML-001: Regression Analysis for KPI Prediction**: The system shall implement regression models to predict key performance indicators (KPIs) such as Average Handle Time (AHT) for the contact center and App Crash Rate for mobile banking. These models will use relevant features like call volume, agent experience, device type, transaction volume, etc. The predictive models must achieve a Mean Absolute Percentage Error (MAPE) of less than 15% on a held-out test dataset. The specific KPIs to be predicted and the features used will be configurable and documented.

**FR-AIML-002: Clustering for Agent Performance Grouping**: The system shall employ clustering algorithms (e.g., K-Means) to group contact center agents based on their performance metrics (e.g., AHT, CSAT, First Call Resolution). The system should suggest an optimal number of clusters (e.g., 3-5 groups like 'High Performers', 'Average Performers', 'Needs Improvement') and allow for the characteristics of each cluster to be analyzed. The stability of clusters should be validated over time.

**FR-AIML-003: Clustering for Customer Behavior Segmentation**: The system shall use clustering techniques to segment customers based on their IVR interaction patterns (e.g., common navigation paths, drop-off points) and mobile banking transaction behavior (e.g., types of transactions, frequency, value). These segments will help in understanding different customer personas and tailoring services. The resulting clusters must be interpretable and actionable from a business perspective, with clear differentiation between segments.

**FR-AIML-004: Anomaly Detection in KPIs**: The system shall implement anomaly detection mechanisms (e.g., Isolation Forest, PCA-based methods, or time-series decomposition) to automatically identify significant outliers or unusual patterns in KPIs for both contact center and mobile banking. For instance, it should detect a sudden spike in AHT or an abnormal drop in transaction success rates. The system must achieve a precision of at least 80% and recall of at least 70% in detecting predefined critical anomalies, minimizing false positives to less than 10%.

**FR-AIML-005: Automated Neural Networks (Azure AutoML)**: The system shall leverage Azure AutoML to optimize predictive models, particularly for complex KPIs or sentiment analysis enhancements where applicable. Azure AutoML will be used to explore different algorithms and hyperparameter settings for neural networks and other sophisticated models, aiming to achieve the best possible predictive accuracy (e.g., target R-squared > 0.7 for regression, F1-score > 0.8 for classification tasks).

**FR-AIML-006: MLOps Pipeline Integration**: All AI/ML models (regression, clustering, anomaly detection, custom tone detection) shall be managed through an MLOps pipeline utilizing Azure Machine Learning services. This includes data ingestion from `Calls`, `MobileTransactions`, `IVRInteractions`, feature engineering (e.g., keyword frequency, session duration), model training, versioning, deployment as Azure ML endpoints, and ongoing monitoring for performance degradation or drift. The pipeline must support automated retraining when performance drops below a defined threshold (e.g., 10% decrease in accuracy).

**FR-AIML-007: Model Registry and Management**: The system shall use Azure ML Model Registry to store and version all trained ML models. Metadata for each model, including its name, version, training date, performance metrics, and path/URI, shall be stored in the `MLModels` table in the Azure SQL Server database. This ensures traceability and facilitates model rollback if needed.

**FR-AIML-008: Feature Engineering and Encoding**: The MLOps pipeline shall include robust feature engineering steps. Categorical features (e.g., `CallType`, `TransactionType`, `DeviceType`) must be appropriately encoded (e.g., one-hot encoding, label encoding) before being used in ML models. Details of these encodings and the engineered features shall be documented and potentially stored or referenced in the `FeatureEncodings` table if complex or reusable.

**FR-AIML-009: AI/ML Output Integration with Dashboards**: The insights generated from AI/ML models (e.g., predicted KPI values, agent cluster assignments, customer segments, identified anomalies) shall be made available for display in the customizable React dashboards and Power BI reports. This allows users to visualize and act upon these advanced analytics.

**FR-AIML-010: Explainability for AI/ML Models**: For critical AI/ML models, particularly those influencing decision-making (e.g., agent performance clustering, KPI predictions impacting targets), the system should incorporate or allow for the use of model explainability techniques (e.g., SHAP values, LIME) to understand the key drivers behind model predictions or classifications. This is important for building trust and ensuring fairness. The level of explainability required will be determined on a per-model basis.



#### 3.1.6 MLOps Pipeline

**FR-MLOPS-001: Comprehensive MLOps Framework**: The system shall implement a comprehensive Machine Learning Operations (MLOps) pipeline utilizing Azure Machine Learning services. This pipeline must manage the end-to-end lifecycle of all AI/ML models developed for the platform, including but not limited to regression models for KPI prediction, clustering models for agent and customer segmentation, anomaly detection models, and custom models for tone detection. The MLOps pipeline must ensure reproducibility, reliability, and efficiency in model development, deployment, and maintenance.

**FR-MLOPS-002: Data Ingestion and Preparation**: The MLOps pipeline shall include automated processes for ingesting data from relevant source tables, specifically `Calls`, `MobileTransactions`, and `IVRInteractions` within the Azure SQL Server database. This process must handle data extraction, transformation (e.g., cleaning, normalization), and loading (ETL) into a format suitable for model training and batch scoring. Data versioning capabilities should be considered to ensure reproducibility of experiments.

**FR-MLOPS-003: Feature Engineering and Management**: The pipeline must incorporate robust and repeatable feature engineering steps. This includes creating relevant features from raw data (e.g., calculating keyword frequency from call transcripts, deriving session duration from timestamps, creating interaction-based features for IVR). Engineered features should be documented, and where applicable, a feature store approach (leveraging Azure ML capabilities or a custom solution) should be considered for managing and reusing features across multiple models. The system must handle encoding of categorical features (e.g., `CallType`, `TransactionType`) using techniques like one-hot or label encoding, with these encodings stored or versioned, potentially in the `FeatureEncodings` table as specified in the input document.

**FR-MLOPS-004: Model Training and Retraining Automation**: The MLOps pipeline shall automate the model training process. This includes script-based training routines that can be triggered manually or on a schedule. The pipeline must also support automated model retraining when specific triggers are met, such as significant data drift detected, a predefined schedule (e.g., monthly), or when model performance degrades below a configurable threshold (e.g., a 10% decrease in accuracy or a 15% increase in MAPE compared to the production model). Training runs, including configurations and results, must be logged in Azure ML.

**FR-MLOPS-005: Model Evaluation and Validation**: Before deployment, all trained models must undergo a rigorous evaluation and validation process within the pipeline. This includes assessing performance against predefined metrics (e.g., MAPE for regression, F1-score for classification, silhouette score for clustering) on a held-out test dataset. The validation process must ensure that a new model performs better than or equal to the currently deployed model, or meets a minimum quality bar if it's a new model type. Results of these evaluations must be logged and accessible.

**FR-MLOPS-006: Model Versioning and Registry**: The system shall utilize the Azure ML Model Registry for versioning all trained machine learning models. Each registered model version must be associated with its training script, dataset version, hyperparameters, and performance metrics. This allows for traceability, reproducibility, and the ability to roll back to previous model versions if necessary. Metadata about registered models, including their name, version, URI, and key performance metrics, shall be stored or referenced in the `MLModels` table in the Azure SQL Server database.

**FR-MLOPS-007: Model Deployment to Production Endpoints**: The MLOps pipeline must support the automated deployment of validated and registered models as scalable and secure endpoints using Azure Machine Learning deployment targets (e.g., Azure Kubernetes Service or Azure Container Instances, as appropriate for the workload). These endpoints will be consumed by the FastAPI backend for real-time predictions or batch scoring. The deployment process should include smoke tests to ensure the endpoint is functioning correctly post-deployment.

**FR-MLOPS-008: Model Monitoring and Feedback Loop**: Once deployed, the performance of ML models in production must be continuously monitored. This includes tracking operational metrics (e.g., latency, error rates of the endpoint) and data science metrics (e.g., prediction accuracy, data drift, concept drift). The system must establish a feedback loop where monitoring insights can trigger alerts or automated retraining processes. For instance, if data drift is detected beyond a certain threshold, an alert should be raised, and the model retraining pipeline should be initiated.

**FR-MLOPS-009: Infrastructure as Code (IaC)**: Where feasible, the infrastructure components of the MLOps pipeline (e.g., Azure ML workspaces, compute targets, datastores) should be defined and managed using Infrastructure as Code principles (e.g., using Azure Resource Manager templates or Terraform). This promotes consistency and repeatability across environments (development, staging, production).

**FR-MLOPS-010: Security and Governance**: The MLOps pipeline must adhere to security best practices, including secure management of credentials, role-based access control (RBAC) for Azure ML resources, and logging of all pipeline activities for audit purposes. Governance processes for model approval before deployment should be supported by the pipeline, potentially involving manual approval steps for critical models.



#### 3.1.7 Customizable Dashboards

**FR-CD-001: User-Specific Dashboard Customization**: The system shall allow specified users (Admin, Hameed, Rishi for each tenant) to create, modify, and save personalized dashboard layouts and configurations. Each user must be able to tailor their dashboard view to their specific analytical needs and preferences. User identification for loading and saving these customizations will be achieved via a dropdown menu selection of their predefined user ID (Admin, Hameed, or Rishi) rather than a traditional authentication login. The system must ensure that customizations made by one user do not affect the dashboards of other users, even within the same tenant.

**FR-CD-002: Persistence of Dashboard Configurations**: All user-specific dashboard configurations, including widget selection, widget placement, filter settings, and report configurations, shall be persisted in the Azure SQL Server database. These configurations must be stored in the `DashboardCustomizations` table, specifically within the `DashboardConfig` (for widget layouts) and `ReportConfig` (for saved custom reports) columns, likely as JSON strings. The system must reliably load a user's saved configuration when they select their ID and save any changes made during their session. The `LastUpdated` timestamp in `DashboardCustomizations` must be updated upon each save.

**FR-CD-003: Drag-and-Drop Widget Management**: The React frontend shall provide an intuitive drag-and-drop interface for users to add, remove, and rearrange widgets on their dashboards. Users must be able to select from a predefined library of available widgets (e.g., AHT line chart, sentiment heatmap, key phrase list, IVR sankey diagram). The system should support a responsive grid layout where widgets can be placed and resized (within reasonable constraints) by the user. The state of the widget layout must be accurately saved and restored.

**FR-CD-004: Configurable Filters**: Users shall be able to apply and configure filters to their dashboards and individual widgets. Standard filters must include Tenant (if a user has a view across tenants, though current roles are per-tenant), date range (e.g., today, last 7 days, custom range), KPI type, call type (e.g., inbound/outbound for contact center), and transaction type (for mobile banking). Filter settings must be part of the saved dashboard configuration and automatically applied when the dashboard is loaded. The available filter options should be dynamically populated based on the data (e.g., available KPI types).

**FR-CD-005: Drill-Down Capabilities**: Dashboards and specific widgets must support drill-down functionality. For example, clicking on a KPI value (e.g., overall AHT) in a widget should allow the user to navigate to a more detailed view, such as agent-level AHT data or even individual call-level data contributing to that KPI. Similarly, users should be able to view call transcripts with highlighted key phrases and entities when drilling down from relevant analytics widgets. The drill-down paths and available detail levels must be clearly defined for each KPI and widget type.

**FR-CD-006: AI and Cognitive Services Integration in Widgets**: Dashboard widgets must be capable of displaying outputs from Azure Cognitive Services and the enhanced AI/ML capabilities. This includes visualizing sentiment scores (e.g., as gauges, trend lines, or heatmaps), displaying lists of extracted key phrases and entities, showing detected IVR intents, visualizing IVR node paths (e.g., using sankey diagrams), and presenting predicted KPI values or anomaly alerts. The presentation of this information must be clear, concise, and actionable.

**FR-CD-007: Saved Custom Reports**: Users shall be able to define and save custom report configurations. A custom report configuration would typically involve selecting specific KPIs, grouping dimensions (e.g., by AgentID), and applying filters. These saved report configurations (stored in `DashboardCustomizations.ReportConfig`) should be listable and executable by the user, generating the specified report view within their dashboard environment. An example given is an "Agent Performance" report including AHT and CSAT, grouped by AgentID.

**FR-CD-008: Widget Library**: The system shall provide a library of at least 15 distinct widget types that users can add to their dashboards. These widgets will cover various visualization needs, including line charts, bar charts, pie charts, heatmaps, sankey diagrams, KPI cards (single value display), data tables, text displays (for transcripts or key phrases), and potentially custom widgets for specific AI outputs. The initial set of widgets must cover the primary KPIs and analytics outputs described in this SRS.

**FR-CD-009: Dashboard Performance**: Customized dashboards, even with multiple widgets and filters applied, must load within 10 seconds for typical data volumes and queries. Widget interactions, such as applying a new filter or drilling down, should respond within 5 seconds. Performance testing will be conducted with a dashboard configuration containing at least 10 widgets displaying data over a one-month period.

**FR-CD-010: No Authentication Requirement for Customization Access**: As per the specified constraint, access to dashboard customization features for the predefined users (Admin, Hameed, Rishi) will be granted upon selection of their user ID from a dropdown list within the application. No separate username/password authentication will be required for this specific functionality. The security of these customizations relies on the overall application access control.



#### 3.1.8 React Frontend

**FR-RF-001: Frontend Technology Stack**: The frontend of the analytics platform shall be developed as a single-page application (SPA) using React (version 17 or higher). Standard JavaScript (ES6+) or TypeScript should be used for development. The frontend must utilize modern React best practices, including functional components, hooks, and context API or a state management library (e.g., Redux, Zustand) if deemed necessary for managing complex application state. The UI component library (e.g., Material-UI, Ant Design) can be used to ensure a consistent look and feel, and rapid development, subject to approval.

**FR-RF-002: Dashboard Customization Interface**: The React frontend shall provide the primary interface for users (Admin, Hameed, Rishi) to customize their dashboards. This includes implementing the drag-and-drop functionality for widget management (add, remove, rearrange, resize) as specified in FR-CD-003, using libraries like `react-beautiful-dnd` or similar. The interface must be intuitive and allow users to easily manage their dashboard layout and widget configurations. Changes made by the user must be reflected immediately on the UI and an explicit save action (e.g., a "Save Dashboard" button) must be provided to persist these changes via FastAPI backend calls to the `DashboardCustomizations` table.

**FR-RF-003: User Selection for Customization**: The frontend shall implement the user selection mechanism (dropdown list containing "Admin", "Hameed", "Rishi") for loading and saving user-specific dashboard customizations, as per FR-CD-001 and FR-CD-010. Upon selection, the frontend must fetch and render the corresponding user's saved dashboard configuration from the backend.

**FR-RF-004: Widget Rendering and Interaction**: The frontend must be capable of rendering all widget types defined in the widget library (FR-CD-008). This includes rendering various chart types (line, bar, pie, heatmap, sankey) using a charting library like Recharts or similar, displaying KPI cards, data tables, and textual information. Widgets must be interactive, supporting tooltips on hover for chart data points and click actions for drill-down functionality (FR-CD-005).

**FR-RF-005: Drill-Down Navigation**: The React application shall manage navigation for drill-down views. When a user clicks on a KPI or widget element that supports drill-down, the frontend must fetch the detailed data from the appropriate FastAPI endpoint and render it in a new view or an expanded section within the current dashboard. This includes displaying detailed tables, call transcripts with highlighted key phrases/entities, or more granular charts.

**FR-RF-006: Real-time Cognitive Services Integration Display**: The frontend must display outputs from Azure Cognitive Services in real-time or near real-time where applicable. This includes dynamically updating sentiment scores, displaying lists of key phrases and entities as they are processed, and showing IVR node paths in sankey diagrams. For features like live call transcription or sentiment updates, WebSockets or frequent polling (if WebSockets are not feasible) shall be used to receive updates from the backend and refresh the relevant UI components without requiring a full page reload. The display of this information must be clear and integrated seamlessly into the dashboard widgets.

**FR-RF-007: Filter Implementation**: The frontend shall implement user-configurable filters as specified in FR-CD-004. This includes providing UI elements (e.g., dropdowns, date pickers) for selecting filter criteria such as tenant, date range, KPI type, call type, and transaction type. Applying a filter must dynamically update the data displayed in all relevant dashboard widgets. Filter states must be persisted as part of the dashboard configuration.

**FR-RF-008: Trend Analysis Visualization**: The frontend shall support the visualization of trends for KPIs, allowing users to view data on a day-on-day, month-on-month, and year-on-year basis. This typically involves line charts or bar charts showing KPI values over selected time periods, with options to compare against previous periods.

**FR-RF-009: API Integration with FastAPI Backend**: The React frontend will communicate exclusively with the FastAPI backend via RESTful API calls for all data retrieval (KPIs, analytics, dashboard configurations) and data submission (saving dashboard configurations). All API calls must handle responses gracefully, including displaying appropriate error messages to the user in case of API failures or network issues. Authentication/authorization for API calls, if any beyond tenant/user context, will be handled as per backend specifications.

**FR-RF-010: Responsive Design**: The frontend application must be responsive and provide a usable experience on common desktop screen resolutions (e.g., 1366x768, 1920x1080). While a full mobile-specific design is not explicitly required by the input document, the application should degrade gracefully on smaller tablet-sized screens if possible. The primary target is desktop usage.

**FR-RF-011: Performance and Load Times**: The initial load time for the React application (including fetching initial dashboard configuration for a user) should be under 7 seconds on a standard corporate network connection. Subsequent interactions, such as applying filters or opening new widgets, should render updates within 3 seconds. Performance will be benchmarked using browser developer tools.

**FR-RF-012: Error Handling and User Feedback**: The frontend must provide clear and user-friendly feedback for all operations, including success messages (e.g., "Dashboard saved successfully") and error messages (e.g., "Failed to load KPI data"). It should handle API errors, validation errors, and unexpected exceptions gracefully, preventing application crashes and guiding the user where possible.



#### 3.1.9 FastAPI Backend

**FR-FB-001: Backend Technology and Framework**: The backend of the analytics platform shall be developed using Python (version 3.7 or higher) and the FastAPI web framework. The backend must be designed to be high-performance, scalable, and maintainable, adhering to FastAPI best practices, including the use of Pydantic models for data validation and serialization, and asynchronous programming (`async`/`await`) for I/O-bound operations to ensure responsiveness.

**FR-FB-002: API Endpoints for KPI Retrieval**: The FastAPI backend shall expose secure and efficient RESTful API endpoints for retrieving all calculated Key Performance Indicators (KPIs) for both contact center and mobile banking operations. These endpoints must support filtering by TenantID, date ranges, specific KPI types, and other relevant dimensions (e.g., AgentID, TransactionType). The API response for KPI data should be structured (e.g., JSON) for easy consumption by the React frontend and Power BI. Endpoints should support fetching aggregated KPI values as well as data for trend analysis (e.g., time-series data for a specific KPI).

**FR-FB-003: API Endpoints for Azure Cognitive Services Integration**: The backend shall provide API endpoints to manage interactions with Azure Cognitive Services. This includes endpoints for: 
    a.  Submitting call audio (or references to audio paths) for transcription via Azure Speech Service (FR-ACS-001).
    b.  Submitting text (from transcripts or mobile feedback) for analysis (sentiment, key phrases, entities) via Azure Text Analytics (FR-ACS-003, FR-ACS-004, FR-ACS-005).
    c.  Submitting IVR interaction data for intent detection via LUIS (FR-ACS-006).
    d.  Retrieving the results of these Cognitive Services operations. 
The sample code in the input document (`/transcribe_call` and `/analyze_call`) provides a baseline for these types of endpoints. These endpoints must securely handle Azure service keys and manage API responses, including errors from Azure services.

**FR-FB-004: API Endpoints for Enhanced AI/ML Capabilities**: The backend shall expose API endpoints to serve predictions and insights from the deployed AI/ML models (FR-AIML-001 to FR-AIML-005, FR-AIML-009). This includes endpoints for: 
    a.  Retrieving predicted KPI values.
    b.  Fetching agent cluster assignments or customer segment information.
    c.  Obtaining lists of detected anomalies in KPIs.
    These endpoints will typically invoke the Azure ML deployed model endpoints.

**FR-FB-005: API Endpoints for Customizable Dashboard Management**: The backend must provide API endpoints to support the customizable dashboard functionality of the React frontend. This includes endpoints for: 
    a.  Fetching a user's (Admin, Hameed, Rishi, identified by UserID and TenantID) saved dashboard configuration (`DashboardConfig` and `ReportConfig` from `DashboardCustomizations` table) (FR-CD-002).
    b.  Saving a user's updated dashboard configuration to the database (FR-CD-002).
    These endpoints will handle JSON data representing the dashboard structure and widget settings.

**FR-FB-006: API Endpoints for Drill-Down Data**: To support drill-down functionality in the frontend (FR-CD-005, FR-RF-005), the backend shall provide specific API endpoints that can retrieve detailed data. For example, an endpoint `/kpi-details/{tenant_id}/{kpi}/{date}` (as per sample code) to get agent-level values for a KPI on a specific date, or an endpoint to fetch a specific call transcript and its associated analytics (`CallTranscriptions` data).

**FR-FB-007: API Endpoints for IVR Analytics**: The backend shall provide API endpoints to retrieve processed IVR analytics data, such as node sequences, drop-off points, and customer cluster information based on IVR behavior, for visualization in the frontend (e.g., sankey diagrams) (FR-RF-006, FR-IVA-001).

**FR-FB-008: API Endpoints for Transaction Data**: Endpoints will be required to fetch mobile transaction data (`MobileTransactions`) for display and analysis, potentially with filtering capabilities based on transaction type, status, date range, etc.

**FR-FB-009: Database Interaction**: The FastAPI backend will be responsible for all interactions with the Azure SQL Server database. This includes querying data for KPIs, analytics, and configurations, as well as writing data (e.g., saving dashboard customizations, storing ML model metadata). Database connections must be managed efficiently (e.g., using connection pooling) and all SQL queries must be parameterized to prevent SQL injection vulnerabilities. The use of an ORM like SQLAlchemy or a query builder can be considered but direct, optimized SQL queries are also acceptable, especially for complex analytical queries.

**FR-FB-010: Data Validation and Serialization**: All incoming API request data must be rigorously validated using Pydantic models to ensure data integrity and type correctness. Similarly, all API responses must be serialized into a consistent JSON format using Pydantic models.

**FR-FB-011: Error Handling and Logging**: The backend API shall implement robust error handling. It must return appropriate HTTP status codes (e.g., 200 OK, 201 Created, 400 Bad Request, 401 Unauthorized, 403 Forbidden, 404 Not Found, 500 Internal Server Error) and meaningful error messages in JSON format. Comprehensive logging of API requests, responses, errors, and significant backend events must be implemented, integrating with Azure Monitor or Application Insights for centralized logging and monitoring.

**FR-FB-012: Performance and Scalability**: Backend API endpoints must be performant. Standard data retrieval endpoints should respond within 2 seconds under typical load (e.g., 50 concurrent users). Endpoints triggering complex calculations or external service calls should respond within 10 seconds or implement an asynchronous pattern (e.g., returning a task ID for polling). The backend application must be designed to be scalable, capable of being deployed with multiple instances on Azure App Service to handle increased load.

**FR-FB-013: Security**: API endpoints must enforce security measures appropriate to the data they handle. While user authentication for dashboard customization is via dropdown, API access itself might require bearer token authentication or other mechanisms if the application is exposed more broadly. TenantID checks must be integral to all data access logic to ensure multi-tenancy security. Sensitive configuration data (e.g., database connection strings, Azure service keys) must be managed securely using Azure Key Vault or environment variables, not hardcoded.



#### 3.1.10 Power BI Integration

**FR-PBI-001: Real-time Dashboard Connectivity**: The system shall support integration with Power BI Service to enable the creation of real-time and interactive dashboards. Power BI dashboards must be able to connect to the Azure SQL Server database (or potentially to specific views or aggregated tables optimized for reporting) to source data for KPIs, Cognitive Services outputs, and AI/ML insights. The connection method should ensure data is refreshed in Power BI dashboards with a maximum latency of 15 minutes for near real-time data, or as configured by the Power BI dataset refresh schedule for less critical data.

**FR-PBI-002: Visualization of Cognitive Services Outputs**: Power BI dashboards must effectively visualize outputs from Azure Cognitive Services. This includes, but is not limited to: 
    a.  Sentiment heatmaps based on `CallTranscriptions.SentimentScore` or mobile feedback sentiment, allowing users to quickly identify areas of high positive or negative sentiment (e.g., by agent, by call type, by transaction type).
    b.  Word clouds generated from `CallTranscriptions.KeyPhrases` and `CallTranscriptions.Entities` (and similar fields in `MobileTransactions`) to highlight frequently occurring terms and topics.
    c.  Sankey diagrams visualizing `IVRInteractions.NodeSequence` to illustrate common customer paths and drop-off points within the IVR system.
    These visualizations must be clear, interpretable, and provide actionable insights.

**FR-PBI-003: KPI Card and Chart Visualization**: Power BI dashboards shall prominently display key performance indicators (KPIs) using appropriate visuals such as KPI cards (for single, important metrics), line charts for trend analysis, bar charts for comparisons, and gauges for performance against targets. All 90 contact center KPIs and 100 mobile banking KPIs (across critical, medium, and low categories) should be representable in Power BI, though specific dashboards will focus on subsets relevant to their purpose.

**FR-PBI-004: Drill-Through Capabilities**: Power BI reports and dashboards must support drill-through functionality. Users should be able to click on a summarized KPI or a visual element (e.g., a bar in a chart representing an agent) and navigate to a more detailed report page showing underlying data. For example, drilling through from an overall CSAT score could lead to a report showing CSAT scores by agent, or further to individual call/transcript details related to low CSAT scores. The drill-through paths must be intuitive and provide contextually relevant information.

**FR-PBI-005: User-Specific Customizations and Slicers**: Power BI dashboards should support user-specific views and customizations where feasible, aligning with the user preference for Power BI. This can be achieved through the use of slicers that allow users to filter data dynamically (e.g., by date range, tenant, agent, call type, sentiment score range). While full drag-and-drop customization like the React frontend is a Power BI feature itself, the provided Power BI templates should be designed to be flexible and allow users to leverage Power BI's native customization capabilities, including saving personalized bookmarks or views of reports.

**FR-PBI-006: Data Analysis Expressions (DAX) for Measures**: Complex calculations and custom measures required for Power BI visualizations that are not directly available as pre-calculated KPIs in the database shall be implemented using Data Analysis Expressions (DAX). The sample DAX provided (`SentimentScore = AVERAGE(CallTranscriptions[SentimentScore])`, `KeyPhraseCount = COUNTROWS(FILTER(CallTranscriptions, CallTranscriptions[KeyPhrases] <> ""))`) illustrates this. All DAX measures must be optimized for performance and accurately reflect the business logic.

**FR-PBI-007: Power BI Templates as Deliverables**: As part of the project deliverables, a set of Power BI template files (.pbit) shall be provided. These templates will include pre-configured data connections (parameterized for server/database names), data models, key DAX measures, and sample dashboard layouts for common analytical scenarios (e.g., Contact Center Overview, Agent Performance, Mobile Banking Trends, Sentiment Analysis). These templates will serve as a starting point for X Bank and Y Bank to develop their specific Power BI reports and dashboards.

**FR-PBI-008: Data Model Optimization for Power BI**: The underlying data model exposed to Power BI (whether direct tables, views, or an intermediate data warehouse layer) must be optimized for Power BI performance. This includes using star or snowflake schemas where appropriate, defining relationships correctly, minimizing cardinality, and ensuring data types are appropriate. This optimization is crucial for responsive dashboards, especially when dealing with large volumes of data.

**FR-PBI-009: Security Integration with Power BI**: Data security, particularly multi-tenancy, must be maintained when data is accessed via Power BI. If Power BI connects directly to the Azure SQL Database, row-level security (RLS) implemented in the database should be leveraged by Power BI to ensure users only see data for their respective tenant(s) based on their Power BI login credentials and database permissions. The specific mechanism for enforcing tenant security in Power BI must be clearly defined and implemented.



#### 3.1.11 Alerts System

**FR-AS-001: Threshold-Based KPI Alerts**: The system shall implement an alerting mechanism that triggers notifications when predefined thresholds for critical Key Performance Indicators (KPIs) are breached. For example, an alert must be generated if Average Handle Time (AHT) exceeds 300 seconds, or if Customer Satisfaction (CSAT) drops below 75% for a specified period. These thresholds must be configurable per KPI and potentially per tenant. The system must allow for defining the condition (e.g., greater than, less than, equal to) and the duration for which the condition must persist before an alert is triggered.

**FR-AS-002: Anomaly Detection Alerts**: The system shall generate alerts when the AI/ML anomaly detection models (as per FR-AIML-004) identify significant and verified anomalies in KPI trends or operational data. For instance, if a sudden, statistically significant spike in call abandonment rate is detected that is not attributable to normal fluctuations, an alert should be raised. The sensitivity of anomaly alerts should be configurable to balance detection rates with false positives.

**FR-AS-003: System Load Alerts**: The platform shall monitor system load, particularly contact center call volume, and generate alerts if predefined load thresholds are exceeded. For example, an alert must be triggered if the total daily call volume exceeds 2,500 calls, or if concurrent active calls surpass a specified limit. This helps in proactively managing resources and identifying potential capacity issues.

**FR-AS-004: Alert Notification Mechanisms**: The system must support configurable notification mechanisms for alerts. Initially, alerts shall be stored in the `Alerts` table in the Azure SQL Server database. The system should also provide a mechanism for these alerts to be surfaced in the React frontend dashboard (e.g., a dedicated alerts panel or notifications). Future enhancements could include email notifications or integration with other incident management systems, but the primary requirement is database storage and UI visibility.

**FR-AS-005: Alert Configuration and Management**: Users with appropriate permissions (e.g., Admin role) shall be able to configure alert rules, including selecting the KPI or data source, setting thresholds or anomaly detection sensitivity, defining the severity of the alert (e.g., critical, warning, informational), and specifying notification preferences (if multiple mechanisms are supported). A user interface for managing alert rules (create, view, edit, delete) must be provided, likely within the React frontend.

**FR-AS-006: Alert Logging and History**: All generated alerts, including their timestamp, type (threshold, anomaly, load), severity, the KPI or data point that triggered it, the value at the time of trigger, and the tenant ID, must be logged persistently in the `Alerts` table. This table will serve as an audit trail and allow for historical analysis of alert occurrences. The system should retain alert history for at least 12 months.

**FR-AS-007: Alert Acknowledgment and Resolution Tracking (Future Consideration)**: While not explicitly detailed in the input for immediate implementation, the design should consider future capabilities for users to acknowledge alerts and track their resolution status. For the current scope, logging the alert is the primary requirement.

**FR-AS-008: Implementation via Stored Procedures and Azure Functions**: As suggested in the input document, the alert generation logic, particularly for threshold-based KPI alerts and potentially for polling anomaly detection results, can be implemented using Azure SQL Server stored procedures (for database-centric checks) and Azure Functions (for event-driven or scheduled checks and for orchestrating notifications). Azure Functions can monitor data streams or scheduled checks and write to the `Alerts` table and trigger other notification actions.

**FR-AS-009: Alert Prioritization and Severity**: The system must allow for defining different severity levels for alerts (e.g., High, Medium, Low). This will enable users to prioritize their responses based on the potential impact of the event that triggered the alert. The severity level should be displayed alongside the alert information in the UI and stored in the `Alerts` table.



#### 3.1.12 Synthetic Data Generator

**FR-SDG-001: Synthetic Data Generation Capability**: The system shall include a Python-based script for generating synthetic data for testing, demonstration, and development purposes. This script must be capable of producing realistic-looking data for contact center calls, mobile banking transactions, call transcriptions (including associated Cognitive Services outputs like sentiment, key phrases, and entities), and IVR interactions. The generated data should align with the schemas of the target tables (`Calls`, `MobileTransactions`, `CallTranscriptions`, `IVRInteractions`, etc.) in the Azure SQL Server database.

**FR-SDG-002: Utilization of Faker Library**: The synthetic data generator shall utilize the Faker library (or a similar robust data generation library) to produce varied and plausible data for fields such as names, addresses (if needed, though not explicitly in core tables), dates, times, text sentences (for transcripts), and other common data types. The generation logic should aim for data that mimics real-world distributions where possible, e.g., call durations, transaction amounts within certain ranges.

**FR-SDG-003: Azure Text-to-Speech for Call Audio (Optional Enhancement)**: While the primary focus is on generating structured data and text-based Cognitive Services outputs, the input document mentions Azure Text-to-Speech for calls in the App Builder Prompt (Section 11). If feasible within the project scope, the synthetic data generator could optionally include functionality to generate sample audio snippets for calls using Azure Text-to-Speech, which could then be used for testing the STT pipeline. This is an enhancement and not a core requirement if it significantly increases complexity beyond generating the `CallTranscriptions` data directly.

**FR-SDG-004: Generation of Cognitive Services Outputs**: A key function of the synthetic data generator is to produce synthetic data for fields that would normally be populated by Azure Cognitive Services. This includes generating plausible `TranscriptText`, `SentimentScore` (e.g., random floats between -1 and 1), `KeyPhrases` (e.g., JSON arrays of random relevant words), `Entities` (JSON arrays of fake entities like account numbers or dates), `Tone`, `SpeakerDiarization` data, and `Intent` for IVR interactions. The example code for `generate_transcription_data` in the input document (Section 10) provides a template for this, which should be expanded to cover all relevant fields and tables.

**FR-SDG-005: Tenant-Specific Data Generation**: The synthetic data generator must be capable of generating data for specific tenants (X Bank, Y Bank) by accepting TenantID as a parameter. This ensures that generated test data is correctly associated with a tenant and can be used for testing multi-tenancy features.

**FR-SDG-006: Configurable Number of Records**: The script shall allow the user to specify the number of records to generate for each data type (e.g., number of calls, number of mobile transactions). This provides flexibility for creating datasets of different sizes for various testing scenarios (e.g., small datasets for unit tests, larger datasets for performance tests).

**FR-SDG-007: Data Consistency and Referential Integrity**: The generated synthetic data should maintain basic consistency and referential integrity where feasible. For example, if a synthetic call record is generated in the `Calls` table, corresponding synthetic records should be generated in `CallTranscriptions` and `IVRInteractions` (if applicable for that call type) with matching `CallID`s. Timestamps across related records should be logical (e.g., `EndTime` after `StartTime`).

**FR-SDG-008: Logging of Synthetic Data Generation**: The execution of the synthetic data generator script, including the types and volumes of data generated and the target TenantID, shall be logged. These logs should be stored in the `SyntheticDataLogs` table in the Azure SQL Server database, as specified in the input document. This provides an audit trail of synthetic data creation.

**FR-SDG-009: Script Deliverable and Execution**: The synthetic data generator shall be delivered as a standalone Python script (or a set of scripts). Clear instructions on how to configure and run the script must be provided as part of the project documentation. The script should be executable from a standard Python environment with the necessary libraries (Faker, NumPy, Pandas, pyodbc, potentially Azure SDK for Text-to-Speech if implemented) installed.

**FR-SDG-010: Data Realism for AI/ML Testing**: While perfect realism is not expected, the synthetic data for features used in AI/ML models (e.g., call features for AHT prediction, IVR patterns for clustering) should be sufficiently diverse and representative to allow for meaningful testing of the MLOps pipeline and model training processes. This might involve defining distributions or patterns for certain key features during generation.



#### 3.1.13 IVR Analytics

**FR-IVA-001: IVR Interaction Data Capture and Storage**: The system shall capture detailed data from customer interactions with the Interactive Voice Response (IVR) system. This data must include, at a minimum, the `CallID` (linking to the main call record), `TenantID`, the sequence of IVR nodes selected or traversed by the customer (`NodeSequence`, likely stored as a JSON array or structured string), the specific node where the customer dropped off or exited the IVR (`DropOffNode`), the total time spent in the IVR (`InteractionTime` in seconds), and the `StartTime` of the IVR interaction. This data shall be stored in the `IVRInteractions` table in the Azure SQL Server database.

**FR-IVA-002: IVR Intent Detection using LUIS**: As specified in FR-ACS-006, the system shall integrate with Azure LUIS to detect customer intents based on their interactions within the IVR (e.g., spoken responses or complex DTMF sequences that map to intents). The detected intent (e.g., “check balance,” “technical support,” “make payment”) shall be stored in the `IVRInteractions.Intent` field. The accuracy of intent detection must meet the criteria set in FR-ACS-006 (at least 85% for top 10 intents).

**FR-IVA-003: Analysis of IVR Node Selection Patterns**: The system must provide analytical capabilities to identify common IVR navigation paths, frequently used nodes, and common sequences leading to specific outcomes (e.g., successful self-service, transfer to agent, drop-off). This analysis will help in understanding customer journeys within the IVR and identifying areas for optimization. Results of this analysis should be queryable and visualizable.

**FR-IVA-004: Identification of IVR Drop-Off Points**: The platform shall analyze IVR interaction data to pinpoint common nodes or stages where customers tend to drop off (abandon the call or IVR process). This information is critical for identifying points of friction or confusion in the IVR flow. The system should be able to report on the top N drop-off nodes by volume and percentage of total IVR interactions.

**FR-IVA-005: Visualization of IVR Flows (Sankey Diagrams)**: The system shall support the visualization of IVR customer flows, including node sequences and drop-off points, using Sankey diagrams. These diagrams must be renderable in both the React frontend dashboard (FR-RF-006) and Power BI reports (FR-PBI-002). The Sankey diagrams should clearly illustrate the volume of traffic through different IVR paths and highlight significant drop-off locations.

**FR-IVA-006: Clustering of Customers by IVR Behavior**: As part of the enhanced AI/ML capabilities (FR-AIML-003), the system shall support clustering of customers based on their IVR interaction patterns. This could involve features like common paths taken, time spent in IVR, types of intents expressed, or frequency of IVR usage. These customer clusters should provide insights into different IVR user segments (e.g., "efficient self-servers," "struggling users," "quick transfer requesters").

**FR-IVA-007: IVR Performance Metrics**: The system shall calculate and display specific KPIs related to IVR performance. Examples could include: 
    a.  IVR Self-Service Completion Rate (percentage of IVR interactions resolved without agent transfer).
    b.  Average Time in IVR.
    c.  IVR Abandonment Rate (percentage of calls dropped within the IVR).
    d.  Intent Success Rate (percentage of times a detected intent led to a successful outcome or appropriate routing).
    These metrics should be available for reporting and dashboard display, filterable by tenant and time period.

**FR-IVA-008: Correlation of IVR Data with Other Analytics**: The system should allow for the correlation of IVR interaction data with other contact center analytics. For example, analyzing if calls originating from specific IVR drop-off points have higher AHT or lower CSAT scores when they reach an agent. This provides a more holistic view of the customer journey and the impact of IVR experience on overall contact center performance.



### 3.2 Non-Functional Requirements

#### 3.2.1 Database Requirements

**NFR-DB-001: Database Management System**: The analytics platform shall exclusively use Microsoft Azure SQL Server as its backend database management system (DBMS). This aligns with the specified technology stack and leverages Azure's managed database services for reliability, scalability, and security. The specific edition and service tier of Azure SQL Server will be determined based on performance, storage, and availability requirements identified during the design and deployment planning phases, but must support all required features like row-level security and geo-redundancy as mentioned in the deployment section of the input document.

**NFR-DB-002: Database Schema**: The database schema shall be based on the tables and fields detailed in the input document (Section 5: Updated Database Schema, including `Tenants`, `Users`, `Agents`, `Calls`, `Customers`, `CallTranscriptions`, `QualityCompliance`, `Shifts`, `MobileTransactions`, `IVRInteractions`, `KPIMetrics`, `Alerts`, `MLModels`, `FeatureEncodings`, `DashboardCustomizations`, `SyntheticDataLogs`). All tables must include a `TenantID` column to support multi-tenancy and data isolation. Primary keys, foreign keys, indexes, and appropriate data types must be implemented to ensure data integrity, query performance, and efficient storage. The schema must be version controlled and documented.

**NFR-DB-003: Data Integrity**: The database shall enforce data integrity through mechanisms such as primary keys, foreign key constraints, unique constraints, check constraints, and not-null constraints where appropriate. Business rules that can be enforced at the database level to maintain data consistency should be implemented (e.g., ensuring `EndTime` is after `StartTime`). Data validation should primarily occur at the application layer (FastAPI backend), but database-level constraints will serve as a secondary safeguard.

**NFR-DB-004: Transactionality (ACID Properties)**: All database operations that involve multiple steps or modify critical data (e.g., saving complex dashboard configurations, logging critical alerts along with related state changes) must be performed within atomic transactions to ensure ACID (Atomicity, Consistency, Isolation, Durability) properties. This guarantees that operations are either fully completed or fully rolled back in case of errors, maintaining data consistency.

**NFR-DB-005: Query Performance**: Database queries, particularly those backing the React frontend dashboards and Power BI reports, must be optimized for performance. Standard dashboard data retrieval queries (e.g., fetching KPIs for the last 30 days for a user) should execute within 1 second on average under typical load conditions. Complex analytical queries or those spanning large historical datasets should execute within 5 seconds. This will be achieved through appropriate indexing strategies (e.g., clustered and non-clustered indexes, columnstore indexes for analytical workloads where beneficial), query optimization, and potentially the use of optimized views or materialized views for frequently accessed aggregated data.

**NFR-DB-006: Data Storage Capacity and Growth**: The database must be configured with sufficient initial storage capacity to accommodate current data volumes and projected data growth for at least 24 months, considering 2,000 daily calls, mobile transactions, and associated analytical data. Azure SQL Server's auto-scaling capabilities for storage should be leveraged where appropriate, and storage consumption must be monitored. Data retention policies (e.g., 24 months for historical KPIs as per FR-CCA-007 and FR-MBA-007) will be implemented, potentially involving archiving or purging older data if necessary, with clear procedures defined.

**NFR-DB-007: Backup and Recovery**: The Azure SQL Server instance must be configured with automated backup policies to ensure data durability and support point-in-time recovery (PITR). The backup frequency and retention period must meet the business continuity objectives, aiming for a Recovery Point Objective (RPO) of no more than 1 hour and a Recovery Time Objective (RTO) of no more than 4 hours for critical data. Geo-redundant backups are required as per the deployment section of the input document to protect against regional outages.

**NFR-DB-008: Database Indexing Strategy**: A comprehensive indexing strategy shall be developed and implemented to support efficient data retrieval for all query patterns, including those from the frontend, backend API, Power BI, and analytical processes. This strategy will be reviewed and tuned periodically based on query performance monitoring. Over-indexing and under-indexing will be avoided.

**NFR-DB-009: Connection Management**: The FastAPI backend application shall use efficient database connection pooling to manage connections to Azure SQL Server. This will minimize the overhead of establishing new connections for each request and improve application responsiveness and scalability. Connection strings and database credentials must be managed securely, ideally through Azure Key Vault.



#### 3.2.2 Scalability Requirements

**NFR-SC-001: Scalability of Data Processing**: The system must be designed to handle a growth in data volume and processing load. Specifically, it must be able to scale to accommodate a 50% increase in daily call volume (from 2,000 to 3,000 calls/day) and mobile transaction volume over a 12-month period without significant degradation in performance (i.e., KPI calculation times, API response times, and dashboard load times should not increase by more than 20%). Azure services used (e.g., Azure SQL Server, App Service for FastAPI, Azure Functions, Cognitive Services, Azure ML) should be configured with appropriate service tiers and auto-scaling capabilities where available to support this growth.

**NFR-SC-002: Scalability of User Load**: The React frontend and FastAPI backend must support a concurrent user load of at least 100 users per tenant (total 200 users for X Bank and Y Bank initially) performing typical dashboard interactions (viewing KPIs, applying filters, drill-downs) with API response times remaining within the limits specified in FR-FB-012 (2 seconds for standard queries) and frontend load times as per FR-RF-011.

**NFR-SC-003: Scalability for Additional KPIs**: The platform architecture, including the database schema (`KPIMetrics` table structure) and backend processing logic, must be designed to be easily extensible to support the future addition of new KPIs. The input document mentions future scalability for internet banking KPIs, and the knowledge module (user_2) indicates a potential need for 100 internet banking KPIs. The system should allow for the definition and calculation of these new KPIs without requiring major architectural refactoring. The process for adding new KPIs should be documented.

**NFR-SC-004: Scalability of AI/ML Model Serving**: The Azure Machine Learning endpoints serving the AI/ML models must be scalable to handle the expected prediction request volume from the FastAPI backend. This includes configuring appropriate compute resources for the deployed models and leveraging Azure ML's capabilities for auto-scaling inference clusters if necessary. Prediction latency for real-time models should remain consistently low (e.g., under 500ms per request for typical models) even as request volume increases.

**NFR-SC-005: Scalability of Azure Cognitive Services Usage**: The system's usage of Azure Cognitive Services (Speech-to-Text, Text Analytics, LUIS) must be designed with service quotas and limits in mind. The architecture should gracefully handle potential rate limiting (e.g., through retries with exponential backoff) and allow for scaling up service tiers or requesting quota increases as usage grows. The cost implications of increased Cognitive Services usage must also be considered and monitored.

**NFR-SC-006: Horizontal Scalability of Backend Services**: The FastAPI backend application, deployed on Azure App Service, must be designed to be stateless where possible to facilitate horizontal scaling. This means multiple instances of the backend application can run in parallel behind a load balancer to handle increased API request loads. Session state, if any, should be managed externally (e.g., using Azure Cache for Redis) if it cannot be avoided.

**NFR-SC-007: Database Scalability**: Azure SQL Server offers various service tiers and scaling options (e.g., scaling up DTUs/vCores, read replicas for offloading read-heavy workloads). The chosen service tier must support the initial performance requirements, and the system design should allow for leveraging these scaling options as data volume and query load grow. Read replicas can be considered for Power BI reporting workloads to isolate them from transactional workloads if performance becomes a concern.

**NFR-SC-008: Scalability for New Tenants**: While initially supporting two tenants, the multi-tenant architecture (FR-MT-003) should inherently support the addition of new tenants in the future. The process for onboarding a new tenant, including provisioning any necessary tenant-specific configurations or resources, should be efficient and not significantly impact existing tenants. The system should scale to support at least 5-10 tenants without major architectural changes, assuming similar data volumes per tenant.



#### 3.2.3 Security Requirements

**NFR-SEC-001: Data Encryption at Rest**: All sensitive data stored in the Azure SQL Server database, including customer PII (if any, though not explicitly detailed as being stored directly), call transcriptions, mobile transaction details, and user customization data, must be encrypted at rest. Azure SQL Server Transparent Data Encryption (TDE) shall be enabled by default to meet this requirement. Additionally, sensitive fields within tables (e.g., if specific PII were to be stored) should be considered for column-level encryption if TDE is deemed insufficient for specific compliance needs.

**NFR-SEC-002: Data Encryption in Transit**: All data transmitted between the user's browser and the React frontend, between the React frontend and the FastAPI backend, between the FastAPI backend and the Azure SQL Server database, and between the FastAPI backend and any external Azure services (Cognitive Services, Azure ML), must be encrypted in transit using strong encryption protocols, specifically TLS 1.2 or higher. HTTPS must be enforced for all web communications.

**NFR-SEC-003: Multi-Tenant Security and Row-Level Security (RLS)**: As a core security principle for this multi-tenant platform, strict data isolation between tenants (X Bank and Y Bank) must be enforced at all layers. In the Azure SQL Server database, Row-Level Security (RLS) based on `TenantID` must be implemented for all tables containing tenant-specific data. This ensures that database queries, even if inadvertently malformed at the application layer, cannot access data from another tenant. The FastAPI backend must consistently apply `TenantID` filtering in all its database queries.

**NFR-SEC-004: Secure Management of Credentials and Keys**: All sensitive credentials, such as database connection strings, API keys for Azure Cognitive Services, Azure ML service principals, and any other secrets, must not be hardcoded into the application source code or configuration files. These secrets must be securely managed using Azure Key Vault. The FastAPI backend and other Azure services (e.g., Azure Functions, Azure ML pipelines) must be configured to retrieve these secrets from Azure Key Vault at runtime using managed identities or service principals with appropriately restricted permissions.

**NFR-SEC-005: Protection Against Common Web Vulnerabilities**: The React frontend and FastAPI backend must be developed following secure coding practices to protect against common web application vulnerabilities as outlined by OWASP Top 10. This includes, but is not limited to, protection against SQL injection (via parameterized queries and ORM usage), Cross-Site Scripting (XSS) (via proper input sanitization and output encoding in React), Cross-Site Request Forgery (CSRF) (if applicable, though less so for API-centric backends if using token-based auth), and insecure direct object references. Regular security code reviews and vulnerability scanning (static and dynamic analysis) should be part of the development lifecycle.

**NFR-SEC-006: No Initial Authentication for Dashboard Customization - Security Implications**: The requirement for users (Admin, Hameed, Rishi) to access dashboard customization by selecting their ID from a dropdown (FR-CD-010) implies that traditional session-based authentication is bypassed for this specific feature. The security of this mechanism relies on the overall security of the application environment and assumes that access to the application URL itself is controlled. While this is a stated constraint, the design should minimize any potential risks associated with this approach, for example, by ensuring that the user IDs are not easily guessable or enumerable if the list is very long (though here it is short and predefined) and that no sensitive operations beyond dashboard customization can be performed without further authentication if the platform were to be expanded.

**NFR-SEC-007: Role-Based Access Control (RBAC) for Azure Resources**: Access to Azure resources (Azure SQL Server, App Service, Static Web Apps, Cognitive Services, Azure ML, Key Vault, etc.) must be managed using Azure Role-Based Access Control (RBAC). The principle of least privilege must be applied, granting users, service principals, and managed identities only the minimum necessary permissions required to perform their tasks. Administrative access to Azure resources should be tightly controlled and audited.

**NFR-SEC-008: Audit Logging for Security Events**: The system shall implement audit logging for significant security-related events. This includes, but is not limited to, attempts to access data across tenants (if such attempts can be detected), failed API calls due to authorization issues, changes to critical configurations (e.g., alert rules, if an admin interface exists for this), and administrative actions performed on Azure resources. These audit logs should be stored securely, be tamper-evident, and be available for review by security personnel. Azure Monitor and Application Insights can be leveraged for collecting and analyzing these logs.

**NFR-SEC-009: Input Validation**: All user inputs received by the FastAPI backend from the React frontend or other clients must be rigorously validated on the server-side (in addition to any client-side validation). This includes checking data types, lengths, formats, and ranges to prevent malformed data from being processed or stored, which can be a vector for security vulnerabilities. Pydantic models in FastAPI will be the primary mechanism for this.

**NFR-SEC-010: Regular Security Patching and Updates**: All software components, including the operating systems of Azure services (managed by Azure), Python, FastAPI, React, and all third-party libraries and dependencies, must be kept up-to-date with the latest security patches. A process for regularly reviewing and applying updates should be established to mitigate known vulnerabilities.



#### 3.2.4 Deployment Requirements

**NFR-DEP-001: Target Deployment Environment - Azure Cloud**: The entire Enhanced Multi-Tenant Contact Center and Mobile Banking Analytics Platform, including its database, backend services, frontend application, AI/ML models, and alerting mechanisms, shall be deployed exclusively on the Microsoft Azure cloud platform. Specific Azure services, as outlined in the input document (Section 12), must be utilized for each component.

**NFR-DEP-002: Database Deployment - Azure SQL Server**: The backend database shall be deployed using Azure SQL Server. The deployment must include configuration for geo-redundancy, as specified in the input document, to ensure high availability and disaster recovery capabilities across different geographical regions. The service tier and performance level will be selected to meet the performance (NFR-DB-005) and scalability (NFR-SC-007) requirements.

**NFR-DEP-003: Backend Deployment - FastAPI on Azure App Service**: The FastAPI backend application shall be deployed on Azure App Service. The App Service Plan must be chosen to support the required performance, scalability (NFR-SC-006), and availability. Deployment slots (e.g., for staging and production) should be utilized to enable blue/green deployments or A/B testing if required, minimizing downtime during updates. The App Service environment must be configured securely, following Azure best practices.

**NFR-DEP-004: Frontend Deployment - React on Azure Static Web Apps**: The React frontend application shall be deployed using Azure Static Web Apps. This service is optimized for hosting static site content and integrates well with CI/CD pipelines (e.g., from GitHub Actions or Azure DevOps) for automated builds and deployments. Azure Static Web Apps also provides global distribution and SSL certificates by default.

**NFR-DEP-005: Power BI Deployment - Power BI Service**: Power BI reports and dashboards developed for the platform shall be published to the Power BI Service. This allows for sharing, collaboration, and scheduled data refreshes. Workspace organization within Power BI Service should be planned to manage content effectively for X Bank and Y Bank, potentially with separate workspaces per tenant or per functional area.

**NFR-DEP-006: AI/ML Model Deployment - Azure Machine Learning**: All trained AI/ML models shall be deployed as endpoints using Azure Machine Learning services (e.g., Azure Kubernetes Service (AKS) or Azure Container Instances (ACI) managed by Azure ML). The deployment process must be integrated into the MLOps pipeline (FR-MLOPS-007) for automation and version control. Deployed models must be scalable and monitored for performance.

**NFR-DEP-007: Alerts System Deployment - Azure Functions**: The alerting mechanisms, particularly those involving scheduled checks or event-driven logic (FR-AS-008), shall be implemented and deployed using Azure Functions. Azure Functions provide a serverless compute model suitable for these tasks, scaling automatically based on demand. Function Apps must be configured for reliability and secure access to other resources like Azure SQL Server.

**NFR-DEP-008: Infrastructure as Code (IaC) for Deployment**: To ensure consistency, repeatability, and manageability of the Azure infrastructure, the deployment of Azure resources should be automated using Infrastructure as Code (IaC) principles. This can be achieved using Azure Resource Manager (ARM) templates, Bicep, or tools like Terraform. The IaC scripts must be version controlled and cover the provisioning and configuration of all necessary Azure services.

**NFR-DEP-009: CI/CD Pipeline for Automated Deployments**: A Continuous Integration/Continuous Deployment (CI/CD) pipeline shall be established for the FastAPI backend and React frontend applications. This pipeline, likely using Azure DevOps or GitHub Actions, must automate the build, test, and deployment processes. Successful code commits to the main branch (after passing automated tests and code reviews) should trigger automated deployments to staging and then production environments, with appropriate approval gates.

**NFR-DEP-010: Environment Configuration Management**: Configurations for different deployment environments (e.g., development, staging, production) such as database connection strings, API endpoints, and service keys, must be managed externally from the application code. Azure App Service Application Settings, Azure Functions Application Settings, and Azure Key Vault (NFR-SEC-004) shall be used for this purpose. The CI/CD pipeline must be able to apply the correct configuration for each environment during deployment.

**NFR-DEP-011: Deployment Documentation**: Comprehensive deployment documentation shall be provided as part of the project deliverables. This documentation must include step-by-step instructions for deploying all components of the platform, configuring the Azure services, and managing the CI/CD pipeline. It should also cover rollback procedures in case of deployment failures.

**NFR-DEP-012: Zero-Downtime Deployments (Target)**: For critical components like the FastAPI backend and React frontend, the deployment strategy should aim for zero or minimal downtime during updates. Techniques such as blue/green deployments or rolling updates, facilitated by Azure App Service deployment slots or Azure Kubernetes Service for ML models, should be employed to achieve this.



#### 3.2.5 Monitoring Requirements

**NFR-MON-001: Comprehensive System Monitoring**: The platform shall be comprehensively monitored using Azure Monitor and Application Insights. Monitoring must cover all key components, including the Azure SQL Server database, FastAPI backend application (Azure App Service), React frontend application (Azure Static Web Apps), Azure Functions (for alerts), Azure Cognitive Services usage, and Azure Machine Learning model endpoints.

**NFR-MON-002: Infrastructure Performance Monitoring**: Azure Monitor shall be configured to collect and display key performance metrics for the underlying Azure infrastructure. This includes CPU utilization, memory usage, disk I/O, network traffic, and error rates for Azure SQL Server, App Service instances, and Azure Functions. Dashboards and alerts in Azure Monitor should be set up to notify administrators of any infrastructure-level performance issues or resource exhaustion.

**NFR-MON-003: Application Performance Monitoring (APM) for Backend**: Application Insights shall be deeply integrated with the FastAPI backend application to provide Application Performance Monitoring (APM). This must include tracking of API request rates, response times (latency), failure rates, and server-side exceptions. Distributed tracing should be enabled to track requests across different components if the architecture involves microservices or multiple dependent services. Custom events and metrics can be logged from the FastAPI application to Application Insights for more detailed diagnostics.

**NFR-MON-004: Frontend Performance and Usage Monitoring**: Application Insights shall be integrated with the React frontend application to monitor client-side performance and user behavior. This includes tracking page load times, JavaScript errors, API call latencies from the client perspective, and user flows through the application. This data will help identify frontend performance bottlenecks and usability issues.

**NFR-MON-005: Database Performance Monitoring**: Azure SQL Server performance shall be monitored using Azure Monitor and built-in SQL Server tools (e.g., Query Performance Insight, Dynamic Management Views). Key metrics to monitor include query execution times, index fragmentation, deadlocks, connection pool usage, and storage utilization. Alerts should be configured for issues like long-running queries or low storage space.

**NFR-MON-006: Azure Cognitive Services Monitoring**: The usage and performance of Azure Cognitive Services (Speech, Text Analytics, LUIS) shall be monitored through Azure Monitor. This includes tracking the number of API calls, error rates, latency, and costs associated with each service. Alerts should be configured for unexpected spikes in usage, high error rates, or approaching quota limits.

**NFR-MON-007: Azure Machine Learning Model Monitoring**: Deployed Azure Machine Learning model endpoints must be monitored for operational health (e.g., request latency, error rates, CPU/memory usage of the inference cluster) and for model performance (e.g., data drift, concept drift, prediction accuracy degradation over time). Azure ML and Application Insights can be used for this. The MLOps pipeline (FR-MLOPS-008) should include mechanisms for triggering model retraining based on monitoring feedback.

**NFR-MON-008: Alert System Monitoring**: The health and effectiveness of the alerts system itself (FR-AS-001 to FR-AS-009) must be monitored. This includes ensuring that Azure Functions responsible for alert generation are running correctly and that alerts are being logged to the `Alerts` table as expected. The volume and types of alerts generated should also be reviewed periodically to ensure the alerting rules are well-calibrated.

**NFR-MON-009: Centralized Logging**: All application logs (from FastAPI backend, React frontend if applicable, Azure Functions) and infrastructure logs must be centralized, preferably using Azure Log Analytics (part of Azure Monitor). This allows for unified querying and analysis of logs for troubleshooting, security auditing, and operational insights. Logs must include timestamps, severity levels, component names, and relevant contextual information.

**NFR-MON-010: Availability Monitoring**: Key application endpoints (e.g., main dashboard page, critical API endpoints) shall be monitored for availability using Azure Monitor availability tests (e.g., URL ping tests, standard web tests). Alerts must be configured to notify administrators immediately if any key endpoint becomes unavailable or responds with errors consistently.

**NFR-MON-011: Cost Monitoring and Optimization**: Azure Cost Management + Billing tools shall be used to monitor the costs associated with all Azure services used by the platform. Regular reviews of cost reports should be conducted to identify opportunities for cost optimization without compromising performance or availability. Budgets and spending alerts can be configured in Azure Cost Management.

**NFR-MON-012: Monitoring Dashboards**: Customized monitoring dashboards shall be created in Azure Monitor (and potentially in Power BI for a higher-level overview) to provide a consolidated view of the health, performance, and usage of the entire platform. These dashboards should be tailored to the needs of operations teams and administrators, highlighting key metrics and active alerts.



## 4. Other Requirements

### 4.1 Deliverables

Upon completion of the project, the following items shall be delivered to X Bank and Y Bank. These deliverables are intended to provide the necessary assets and documentation to understand, deploy, operate, and maintain the Enhanced Multi-Tenant Contact Center and Mobile Banking Analytics Platform. Each deliverable will be version controlled and provided in an accessible format.

1.  **Database Schema**: A comprehensive document detailing the final Azure SQL Server database schema. This will include definitions for all tables (such as `Tenants`, `Users`, `Agents`, `Calls`, `Customers`, `CallTranscriptions`, `QualityCompliance`, `Shifts`, `MobileTransactions`, `IVRInteractions`, `KPIMetrics`, `Alerts`, `MLModels`, `FeatureEncodings`, `DashboardCustomizations`, `SyntheticDataLogs`), their columns, data types, relationships (primary and foreign keys), indexes, and any implemented row-level security policies or partitioning strategies. This documentation will be crucial for database administration and future development.

2.  **FastAPI Backend Code**: The complete source code for the FastAPI backend application, written in Python. This includes all API endpoint implementations, Pydantic models for data validation and serialization, database interaction logic, integration code for Azure Cognitive Services and Azure Machine Learning, and any business logic implemented in the backend. The code will be well-commented and structured for maintainability.

3.  **React Frontend Code**: The complete source code for the React frontend application. This includes all React components, services for API interaction, state management logic, UI elements for dashboard customization (including drag-and-drop functionality), widget rendering, and visualization of analytics. The code will be organized, commented, and follow modern React development practices.

4.  **Power BI Templates (.pbit files)**: A set of Power BI template files. These templates will provide pre-configured data connections (parameterized for easy setup), a well-defined data model optimized for Power BI, key Data Analysis Expressions (DAX) measures, and sample dashboard layouts for common analytical scenarios related to contact center and mobile banking analytics, including visualizations for Cognitive Services outputs. These templates will enable users to quickly create and customize their own Power BI reports.

5.  **Synthetic Data Generator Script**: The Python script(s) developed for generating synthetic data for calls, transactions, transcriptions (including sentiment, key phrases, entities), and IVR interactions. This deliverable will include the script code and clear instructions on how to configure and run it to populate the database with test data for specific tenants.

6.  **MLOps Pipeline Definition and Scripts**: All scripts, configuration files, and documentation defining the MLOps pipeline implemented using Azure Machine Learning services. This includes scripts for data ingestion, feature engineering, model training, model evaluation, model registration, automated deployment of models as Azure ML endpoints, and model monitoring. This will enable the tenants to manage the lifecycle of their AI/ML models effectively.

7.  **Alert System Configuration and Code**: Documentation and any specific code (e.g., Azure Functions code, SQL stored procedure definitions) related to the implemented alerts system. This includes details on how to configure alert rules for KPI thresholds, anomalies, and system load, and how alerts are logged and surfaced.

8.  **IVR Analytics Documentation**: Documentation detailing the IVR analytics capabilities, including how IVR interaction data is captured, how intents are detected using LUIS, how node selection patterns and drop-off points are analyzed, and how IVR flows are visualized (e.g., in Sankey diagrams). This will also cover any specific IVR performance metrics implemented.

9.  **Azure Deployment Instructions and Infrastructure as Code (IaC) Scripts**: Comprehensive documentation and any associated Infrastructure as Code (IaC) scripts (e.g., ARM templates, Bicep files, or Terraform configurations) required to deploy and configure all Azure resources for the platform. This includes instructions for setting up Azure SQL Server, Azure App Service for the backend, Azure Static Web Apps for the frontend, Azure Machine Learning workspaces, Azure Functions for alerts, and any other necessary Azure services. Instructions for configuring the CI/CD pipeline will also be included.

10. **User Manual / System Documentation**: A user manual or system documentation covering key aspects of the platform, including how to use the customizable dashboards, interpret the analytics and KPI visualizations, understand the AI/ML insights, and manage alert configurations (if applicable to end-users). This documentation will be aimed at the target users (Admin, Hameed, Rishi) and system administrators.

